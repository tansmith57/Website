---
title: 'Project 2: Modeling, Testing, and Predicting'
author: "Tanner Smith (ts34686)"
date: "2020-05-01"
output:
  pdf_document: default
  html_document: default
---



<div id="introduction" class="section level1">
<h1>Introduction</h1>
<pre class="r"><code>CO2 &lt;- as.data.frame(CO2)
head(CO2)</code></pre>
<pre><code>##   Plant   Type  Treatment conc uptake
## 1   Qn1 Quebec nonchilled   95   16.0
## 2   Qn1 Quebec nonchilled  175   30.4
## 3   Qn1 Quebec nonchilled  250   34.8
## 4   Qn1 Quebec nonchilled  350   37.2
## 5   Qn1 Quebec nonchilled  500   35.3
## 6   Qn1 Quebec nonchilled  675   39.2</code></pre>
<p>The dataset chosen for this project is the CO2 dataset which has data recorded from an experiment on cold tolerance on <em>Echinochloa crus-galli</em>. There are 5 variables with 84 observations in this dataset. the code chunk above shows the first 6 lines of this dataset which shows the different variables. The plant variable is just a classification that indicates the individual plants tested on. The type variable shows whether the plant originated from Quebec or Mississippi. The treatment variable shows whether the plant recieved the treatment of being nonchilled or chilled. The conc variable shows the amount of ambient carbon dioxide concentration the plant was provided with. The uptake variable shows the carbon dioxide uptake rates considering the ambient carbon dioxide and treatment for the plant.</p>
</div>
<div id="manova-and-anova" class="section level1">
<h1>MANOVA and ANOVA</h1>
<div id="manova" class="section level2">
<h2>MANOVA</h2>
<pre class="r"><code>man1&lt;-manova(cbind(conc,uptake)~Treatment, data=CO2)
summary(man1)</code></pre>
<pre><code>## Df Pillai approx F num Df den Df Pr(&gt;F)
## Treatment 1 0.13313 6.22 2 81 0.003069 **
## Residuals 82
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<p>The MANOVA showed significant results which means at least one of conc or uptake differs by the treatment. A univariate ANOVA must be performed to find out which part is significant.</p>
</div>
<div id="univariate-anova" class="section level2">
<h2>Univariate ANOVA</h2>
<pre class="r"><code>summary.aov(man1)</code></pre>
<pre><code>## Response conc :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## Treatment 1 0 0 0 1
## Residuals 82 7268400 88639
##
## Response uptake :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## Treatment 1 988.1 988.11 9.2931 0.003096 **
## Residuals 82 8718.9 106.33
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<p>Only uptake ended up being significant following the univariate ANOVA. A post-hoc t test on the uptake variable must be performed now.</p>
</div>
<div id="post-hoc-t-test" class="section level2">
<h2>Post-hoc t test</h2>
<pre class="r"><code>pairwise.t.test(CO2$uptake, CO2$Treatment, p.adj = &quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  CO2$uptake and CO2$Treatment 
## 
##         nonchilled
## chilled 0.0031    
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>.05/5</code></pre>
<pre><code>## [1] 0.01</code></pre>
<pre class="r"><code>1-.95^5</code></pre>
<pre><code>## [1] 0.2262191</code></pre>
<p>Each treatment was found to differ for the uptake. The total number of test ran was 5 test (1 MANOVA, 2 ANOVA, and 2 t tests). This number of test will be used to adjust significance with the bonferroni correction and find the probability for a Type 1 error. The difference for the t tests was found to be significant after adjusting for multiple comparisons throughout this process using the bonferroni correction (.05/5). The probability of a Type I error was found to be 0.2262191.</p>
</div>
<div id="assumptions" class="section level2">
<h2>Assumptions</h2>
<p>The assumptions for the MANOVA were likely not met because there are so many of them. Overall, this is a random sample with independent observations which is a key assumption in most types of hypothesis testing. There was homogeneity of within-group covariance matrices. There was good equal variance throughout the dataset.</p>
</div>
</div>
<div id="randomization-test" class="section level1">
<h1>Randomization Test</h1>
<pre class="r"><code>CO2 %&gt;% group_by(Treatment)%&gt;%summarize(m=mean(uptake))%&gt;%summarize(diff(m))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   `diff(m)`
##       &lt;dbl&gt;
## 1     -6.86</code></pre>
<pre class="r"><code>rand_dist&lt;-vector()
for(i in 1:5000){
new&lt;-data.frame(uptake=sample(CO2$uptake),Treatment=CO2$Treatment)
rand_dist[i]&lt;-mean(new[new$Treatment==&quot;chilled&quot;,]$uptake)-
              mean(new[new$Treatment==&quot;nonchilled&quot;,]$uptake)}
mean(rand_dist&gt;6.859524 | rand_dist&lt; -6.859524)</code></pre>
<pre><code>## [1] 0.0038</code></pre>
<pre class="r"><code>{hist(rand_dist,main=&quot;&quot;,ylab=&quot;&quot;); abline(v = c(-6.859524,6.859524),col=&quot;red&quot;)}</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;" /> The null hypothesis for this test is the difference in mean uptake between the chilled and nonchilled plants will be as extreme as the observed model after the randimization test. The alternative hypothesis states that the difference in means would not be as extreme. After the randimization test was ran, the p-value was found to be 0.0042. This means that only a proportion of 0.0042 had mean differences as extreme as the one observed. The null hypothesis is rejected and the difference in means after the randomization test is not as extreme. The graph above illustrates this result very well with the red lines representing the test statistic.</p>
</div>
<div id="linear-regression" class="section level1">
<h1>Linear Regression</h1>
<pre class="r"><code>CO2 &lt;- CO2 %&gt;% mutate(conc_c = conc-mean(conc))
fit&lt;-lm(uptake ~ Treatment+conc_c+Type + Treatment*conc_c + Type*conc_c, data=CO2)
summary(fit)</code></pre>
<pre><code>##
## Call:
## lm(formula = uptake ~ Treatment + conc_c + Type +
Treatment *
## conc_c + Type * conc_c, data = CO2)
##
## Residuals:
## Min 1Q Median 3Q Max
## -14.8134 -3.3982 0.6577 4.1964 11.8693
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 36.972619 1.138018 32.489 &lt; 2e-16 ***
## Treatmentchilled -6.859524 1.314070 -5.220 1.44e-06 ***
## conc_c 0.025174 0.003869 6.507 6.72e-09 ***
## TypeMississippi -12.659524 1.314070 -9.634 6.40e-15 ***
## Treatmentchilled:conc_c -0.004188 0.004467 -0.937 0.351
## conc_c:TypeMississippi -0.010699 0.004467 -2.395 0.019 *
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 6.022 on 78 degrees of freedom
## Multiple R-squared: 0.7086, Adjusted R-squared: 0.6899
## F-statistic: 37.94 on 5 and 78 DF, p-value: &lt; 2.2e-16</code></pre>
<p>This linear regression was ran predicting the uptake value from the treatment, type, and carbon diopxide concentration (mean centered). This regression was also ran from the interaction between conc and type and conc and treatment. The conc term was meaqn centered to help gain better results.</p>
<div id="coefficient-estimates" class="section level2">
<h2>Coefficient Estimates</h2>
<p>This linear regression makes a linear formula: Uptake = 36.97 - 6.86(chilled) + 0.03(conc_c) - 12.66(Mississippi) - 0.004 (chilled<em>conc_c) -0.011(Mississippi</em>conc_c) The intercept, 36.97, is the predicted uptake for a non-chilled plant from Quebec with an average concentration of ambient carbon dioxide. The formula above shows the changes to uptake when considering changes to the factors of the intercept value. If the plant was chilled, a 1 would be placed in the formula anywhere the chilled term is and the uptake would lower by 6.86. If the plant was from Mississippi, a 1 would be placed anywhere the Mississippi term is located and the uptake would lower by 12.66. Any change of the concentration of ambient carbon dioxide away from the average would be multiplied by 0.03 and added to the intercept. the chilled<em>conc_c and Mississippi</em>conc_c terms represent the interaction between those variables.</p>
</div>
<div id="plotting-the-regression" class="section level2">
<h2>Plotting the Regression</h2>
<pre class="r"><code>ggplot(CO2, aes(x=conc_c, y=uptake,group=Treatment))+geom_point(aes(color=Treatment))+
  geom_smooth(method=&quot;lm&quot;,formula=y~x,se=F,fullrange=T,aes(color=Treatment))+
theme(legend.position=c(.9,.19))</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-7-1.png" width="768" style="display: block; margin: auto;" /> This plot shows the regression for uptake when considering the ambient concentration of Carbon Dioxide and the type of treatment.</p>
</div>
<div id="assumptions-1" class="section level2">
<h2>Assumptions</h2>
<pre class="r"><code>fit&lt;-lm(uptake ~ Treatment+conc_c+Type + Treatment*conc_c + Type*conc_c, data=CO2)
resids &lt;- fit$residuals
ggplot()+geom_histogram(aes(resids),bins=12)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-8-1.png" width="768" style="display: block; margin: auto;" /> The data looks fairly normal in this linear regression.</p>
<pre class="r"><code>fit&lt;-lm(uptake ~ Treatment+conc_c+Type + Treatment*conc_c + Type*conc_c, data=CO2)
resids &lt;- fit$residuals
fitvals &lt;- fit$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, color=&#39;red&#39;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-9-1.png" width="768" style="display: block; margin: auto;" /> This graph shows homoskedasticity and theres no true pattern which helps confirm there’s linearity. The graph in the previous section of the regression also shows linearity.</p>
</div>
<div id="robust-standard-errors" class="section level2">
<h2>Robust Standard Errors</h2>
<pre class="r"><code>fit&lt;-lm(uptake ~ Treatment+conc_c+Type + Treatment*conc_c + Type*conc_c, data=CO2)
coeftest(fit, vcov = vcovHC(fit))</code></pre>
<pre><code>##
## t test of coefficients:
##
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 36.9726190 1.3613132 27.1595 &lt; 2.2e-16 ***
## Treatmentchilled -6.8595238 1.3732482 -4.9951 3.514e-06
***
## conc_c 0.0251740 0.0057694 4.3633 3.882e-05 ***
## TypeMississippi -12.6595238 1.3732482 -9.2187 4.065e-14
***
## Treatmentchilled:conc_c -0.0041880 0.0051300 -0.8164
0.41677
## conc_c:TypeMississippi -0.0106989 0.0051300 -2.0856
0.04029 *
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<p>The estimates once adding the standard erros are the same as the original model. Every variable still shows significance except the interaction variable between conc_c and treatment. The standard errors between the original model and this model changed very slightly. The model above represents a better representation of the default standard errors in practice.</p>
</div>
<div id="proportion-of-the-variation" class="section level2">
<h2>Proportion of the Variation</h2>
<pre class="r"><code>fit&lt;-lm(uptake ~ Treatment+conc_c+Type + Treatment*conc_c + Type*conc_c, data=CO2)
summary(fit)$r.sq</code></pre>
<pre><code>## [1] 0.7086153</code></pre>
<p>The proportion of the variation in uptake explained by the model is 0.7086153.</p>
</div>
</div>
<div id="bootstrapped-standard-errors" class="section level1">
<h1>Bootstrapped Standard Errors</h1>
<pre class="r"><code>fit &lt;- lm(uptake ~ Treatment+conc_c+Type + Treatment*conc_c + Type*conc_c, data=CO2)
resids &lt;- fit$residuals 
fitted &lt;- fit$fitted.values 

resid_resamp &lt;- replicate(5000,{
    new_resids &lt;- sample(resids,replace=TRUE) 
    CO2$new_y &lt;- fitted+new_resids 
    fit1 &lt;- lm(new_y ~ Treatment+conc_c+Type + Treatment*conc_c + Type*conc_c, data=CO2) 
    coef(fit1) 
})
resid_resamp%&gt;%t%&gt;%as.data.frame%&gt;%summarize_all(sd)</code></pre>
<pre><code>## (Intercept) Treatmentchilled conc_c TypeMississippi
Treatmentchilled:conc_c
## 1 1.081141 1.265303 0.003719795 1.267544 0.004311742
## conc_c:TypeMississippi
## 1 0.004366716</code></pre>
<p>The bootstrapped standard errors are less than original standard errors and robust standard errors. The differences between them aren’t very large, but there is still a difference. the largest standard errors, which is the robust standard errors, might be the safest to use in practice.</p>
</div>
<div id="logistic-regression" class="section level1">
<h1>Logistic Regression</h1>
<div id="coefficient-estimates-1" class="section level2">
<h2>Coefficient Estimates</h2>
<pre class="r"><code>CO2 &lt;- CO2 %&gt;% mutate(y=ifelse(Treatment==&quot;chilled&quot;,1,0))
fit2 &lt;- glm(y~uptake+Type, data=CO2, family=&quot;binomial&quot;)
exp(coef(fit2))</code></pre>
<pre><code>##     (Intercept)          uptake TypeMississippi 
##      39.6982220       0.8980837       0.2358481</code></pre>
<p>The coefficient estimates are shown in the summary code above for the logistic regression model. The estimates were exponentiated to be able to interpret them. The odds of having a chilled treatment if uptake is 0 and the plant is from Quebec is 39.698. Controlling for type, every one additional point of uptake changes the odds by a factor of 0.898. Controlling for uptake, odds of the chilled treatment for the Mississippi plant is 0.236 times the odds of the Quebec plant.</p>
</div>
<div id="confusion-matrix" class="section level2">
<h2>Confusion Matrix</h2>
<pre class="r"><code>fit2 &lt;- glm(y~ uptake+Type, data=CO2, family=&quot;binomial&quot;)
probs&lt;-predict(fit2,type=&quot;response&quot;) 
table(predict=as.numeric(probs&gt;.5),truth=CO2$y)%&gt;%addmargins</code></pre>
<pre><code>##        truth
## predict  0  1 Sum
##     0   31 14  45
##     1   11 28  39
##     Sum 42 42  84</code></pre>
<pre class="r"><code>(31+28)/84 #accuracy</code></pre>
<pre><code>## [1] 0.702381</code></pre>
<pre class="r"><code>28/42 #TPR</code></pre>
<pre><code>## [1] 0.6666667</code></pre>
<pre class="r"><code>31/42 #TNR</code></pre>
<pre><code>## [1] 0.7380952</code></pre>
<pre class="r"><code>28/39 #PPV</code></pre>
<pre><code>## [1] 0.7179487</code></pre>
<p>A confusion matrix was ran which will help to find certain aspects of the logistic regression. The accuracy is 0.702. The sensitivity is 0.667. The specificity is 0.738. The recall is 0.718.</p>
</div>
<div id="density-of-log-odds" class="section level2">
<h2>Density of Log-odds</h2>
<pre class="r"><code>fit2 &lt;- glm(y~ uptake+Type, data=CO2, family=&quot;binomial&quot;)
CO2$logit&lt;-predict(fit2,type=&quot;link&quot;)

CO2%&gt;%ggplot()+geom_density(aes(logit,color=Treatment,fill=Treatment), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab(&quot;logit (log-odds)&quot;)+
  geom_rug(aes(logit,color=Treatment))+
  geom_text(x=-1,y=.3,label=&quot;TN&quot;)+
  geom_text(x=-.5,y=.1,label=&quot;FN&quot;)+
  geom_text(x=.5,y=.1,label=&quot;FP&quot;)+
  geom_text(x=.5,y=.3,label=&quot;TP&quot;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-15-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="roc-curve-auc" class="section level2">
<h2>ROC Curve &amp; AUC</h2>
<pre class="r"><code>library(plotROC)
fit2 &lt;- glm(y~uptake+Type, data=CO2, family=&quot;binomial&quot;)
prob&lt;-predict(fit2,type=&quot;response&quot;)
ROCplot&lt;-ggplot(CO2)+geom_roc(aes(d=y,m=prob), n.cuts=0)+
  geom_segment(aes(x=0,xend=1,y=0,yend=1),lty=2)
ROCplot</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-16-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.7712585</code></pre>
<p>An ROC curve was made to help test the validity of the model and help calculate the AUC. The AUC was found to be 0.771 through the calculate AUC function in R. This is a fair AUC, so the data is not too bad.</p>
</div>
<div id="fold-cv" class="section level2">
<h2>10-Fold CV</h2>
<pre class="r"><code>set.seed(1234)
k=10

data1&lt;-CO2[sample(nrow(CO2)),]
folds&lt;-cut(seq(1:nrow(CO2)),breaks=k,labels=F)

diags&lt;-NULL
for(i in 1:k){
  train&lt;-data1[folds!=i,]
  test&lt;-data1[folds==i,]
  truth&lt;-test$y
  
  fit2 &lt;- glm(y~uptake+Type, data=train, family=&quot;binomial&quot;)
  probs&lt;- predict(fit2, type=&quot;response&quot;, newdata=test)

diags&lt;-rbind(diags,class_diag(probs,truth))
}

diags%&gt;%summarize_all(mean)</code></pre>
<pre><code>##         acc  sens      spec   ppv       auc
## 1 0.6527778 0.585 0.7216667 0.655 0.7564583</code></pre>
<p>After running a 10-fold CV, the average out-of-sample accuracy was 0.653, sensitivity was 0.585, the recall was 0.655, and the AUC was 0.756. All of these are slightly lower compared to the original model’s test.</p>
</div>
</div>
<div id="lasso" class="section level1">
<h1>Lasso</h1>
<pre class="r"><code>set.seed(1234)
cv.lasso1&lt;-cv.glmnet(x=model.matrix(uptake~.,data=CO2),y=as.matrix(CO2$uptake))
lasso1&lt;-glmnet(x=model.matrix(uptake~.,data=CO2),y=as.matrix(CO2$uptake),alpha=1,
               lambda=cv.lasso1$lambda.1se)
coef(lasso1)</code></pre>
<pre><code>## 19 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                            s0
## (Intercept)       33.94439050
## (Intercept)        .         
## Plant.L           -0.04515013
## Plant.Q            .         
## Plant.C            .         
## Plant^4            .         
## Plant^5            .         
## Plant^6            .         
## Plant^7            .         
## Plant^8            .         
## Plant^9            .         
## Plant^10           .         
## Plant^11           .         
## TypeMississippi  -12.85356245
## Treatmentchilled   .         
## conc               .         
## conc_c             .         
## y                  .         
## logit             -9.00041399</code></pre>
<pre class="r"><code>set.seed(1234)
k=10 
data1&lt;-CO2[sample(nrow(CO2)),]
folds&lt;-cut(seq(1:nrow(CO2)),breaks=k,labels=F) 
diags&lt;-NULL
for(i in 1:k){
  train&lt;-data1[folds!=i,]
  test&lt;-data1[folds==i,]
  fit&lt;-lm(uptake~Type,data=CO2)
  yhat&lt;-predict(fit,newdata=test)
  diags&lt;-mean((test$uptake-yhat)^2)
}

mean(diags)</code></pre>
<pre><code>## [1] 73.93739</code></pre>
<p>A LASSO was ran to try and create a better linear model. The LASSO determined that the Type function was the best to run a regression of uptake with so it was retained. A 10-fold CV was ran on the linear regression, and the Standard Error was found at the end. The standard error was found to be 73.937. This is much higher than the original residual standard error of 6.022 found in the original model. This newly made linear regression is actually a worse fit.</p>
</div>
